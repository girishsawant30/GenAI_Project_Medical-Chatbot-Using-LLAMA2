{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings ## For Converting data to Embeddings\n",
    "from langchain.embeddings.vertexai import VertexAIEmbeddings ## For Converting data to Embeddings with VertexAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings ## For Converting data to Embeddings with OpenAI\n",
    "from langchain.vectorstores import Pinecone # For Vector DB\n",
    "from langchain.vectorstores.pinecone import Pinecone # For Vector DB\n",
    "import pinecone # For Vector DB\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader # For loading the data\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # For splitting the data in chunks\n",
    "from langchain.llms import OpenAI, VertexAI, CTransformers # For reasoning logic\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = load_pdf(\"E:\\Girish Documents\\Study\\Data Science\\DataScience_GenAI_Study\\GenAI_Project_Medical-Chatbot-Using-LLAMA2\\data\")\n",
    "#doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = [doc for doc in doc if doc.page_content.strip()]\n",
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7020"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World!\")\n",
    "print(\"Length:\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Search DB In Pinecone\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    environment=\"gcp-starter\"\n",
    ")\n",
    "index_name=\"medical-bot\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.vectorstores.pinecone import Pinecone\n",
    "\n",
    "docsearch = Pinecone.from_documents(text_chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  [Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'E:\\\\Girish Documents\\\\Study\\\\Data Science\\\\DataScience_GenAI_Study\\\\GenAI_Project_Medical-Chatbot-Using-LLAMA2\\\\data\\\\Medical_book.pdf'}), Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'E:\\\\Girish Documents\\\\Study\\\\Data Science\\\\DataScience_GenAI_Study\\\\GenAI_Project_Medical-Chatbot-Using-LLAMA2\\\\data\\\\Medical_book.pdf'}), Document(page_content=\"GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\\nAllergic rhinitis is commonly triggered by\\nexposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\\nThe presence of an allergen causes the\\nbody's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\\nIgE molecules attach to mast\\ncells, which contain histamine.HistaminePollen grains\\nLymphocyte\\nFIRST EXPOSURE\", metadata={'page': 130.0, 'source': 'E:\\\\Girish Documents\\\\Study\\\\Data Science\\\\DataScience_GenAI_Study\\\\GenAI_Project_Medical-Chatbot-Using-LLAMA2\\\\data\\\\Medical_book.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "query = \"What are Allergies?\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result: \", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this --> \"huggingface-cli login\" in Terminal prompt or conda prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"E:\\Girish Documents\\Study\\Data Science\\llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f'Input Prompt:')\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response: \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
